{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Breast.cancer - 이진분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 입력\n",
    "cancer = load_breast_cancer()\n",
    "df_pre = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "df_pre.head()\n",
    "\n",
    "X = cancer.data\n",
    "Y = cancer.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                1550      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 35)                1785      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                432       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,880\n",
      "Trainable params: 3,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정\n",
    "model = Sequential([\n",
    "    Dense(50, input_dim=30, activation='relu'),\n",
    "    Dense(35, activation='relu'),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 설정\n",
    "import os\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + \"best{epoch:03d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "# checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1)\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.15122, saving model to ./model/best001-2.1512.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.15122 to 0.97820, saving model to ./model/best002-0.9782.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.97820 to 0.88187, saving model to ./model/best003-0.8819.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.88187\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.88187\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.88187 to 0.83331, saving model to ./model/best006-0.8333.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.83331 to 0.66588, saving model to ./model/best007-0.6659.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.66588\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.66588\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.66588\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.66588\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.66588\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.66588\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.66588\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.66588 to 0.58025, saving model to ./model/best015-0.5802.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.58025 to 0.52506, saving model to ./model/best016-0.5251.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.52506 to 0.52187, saving model to ./model/best017-0.5219.hdf5\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.52187\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.52187 to 0.51434, saving model to ./model/best019-0.5143.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.51434 to 0.49338, saving model to ./model/best020-0.4934.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.49338 to 0.48793, saving model to ./model/best021-0.4879.hdf5\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.48793\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.48793\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.48793\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.48793\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.48793\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.48793\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.48793\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.48793 to 0.48056, saving model to ./model/best029-0.4806.hdf5\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.48056 to 0.44455, saving model to ./model/best030-0.4446.hdf5\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.44455 to 0.42854, saving model to ./model/best031-0.4285.hdf5\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.42854 to 0.42167, saving model to ./model/best032-0.4217.hdf5\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.42167 to 0.41805, saving model to ./model/best033-0.4180.hdf5\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.41805\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.41805\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.41805\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.41805\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.41805\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.41805\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.41805\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.41805\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.41805 to 0.40659, saving model to ./model/best042-0.4066.hdf5\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.40659 to 0.38791, saving model to ./model/best043-0.3879.hdf5\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.38791 to 0.37850, saving model to ./model/best044-0.3785.hdf5\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.37850 to 0.37570, saving model to ./model/best045-0.3757.hdf5\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.37570\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.37570\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.37570\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.37570\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.37570\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.37570\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.37570\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.37570 to 0.37170, saving model to ./model/best053-0.3717.hdf5\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.37170 to 0.35722, saving model to ./model/best054-0.3572.hdf5\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.35722 to 0.34878, saving model to ./model/best055-0.3488.hdf5\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.34878 to 0.34600, saving model to ./model/best056-0.3460.hdf5\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.34600\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.34600\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.34600\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.34600\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.34600\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.34600\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.34600 to 0.34345, saving model to ./model/best063-0.3434.hdf5\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.34345 to 0.33292, saving model to ./model/best064-0.3329.hdf5\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.33292 to 0.32542, saving model to ./model/best065-0.3254.hdf5\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.32542 to 0.32154, saving model to ./model/best066-0.3215.hdf5\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.32154 to 0.32101, saving model to ./model/best067-0.3210.hdf5\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.32101\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.32101\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.32101\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.32101\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.32101 to 0.32093, saving model to ./model/best072-0.3209.hdf5\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.32093 to 0.31463, saving model to ./model/best073-0.3146.hdf5\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.31463 to 0.30844, saving model to ./model/best074-0.3084.hdf5\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.30844 to 0.30375, saving model to ./model/best075-0.3037.hdf5\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.30375 to 0.30117, saving model to ./model/best076-0.3012.hdf5\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.30117 to 0.30066, saving model to ./model/best077-0.3007.hdf5\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.30066\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.30066\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.30066\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.30066\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.30066 to 0.29936, saving model to ./model/best082-0.2994.hdf5\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.29936 to 0.29551, saving model to ./model/best083-0.2955.hdf5\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.29551 to 0.29169, saving model to ./model/best084-0.2917.hdf5\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.29169 to 0.28876, saving model to ./model/best085-0.2888.hdf5\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.28876 to 0.28713, saving model to ./model/best086-0.2871.hdf5\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.28713 to 0.28676, saving model to ./model/best087-0.2868.hdf5\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.28676\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.28676\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.28676\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.28676 to 0.28634, saving model to ./model/best091-0.2863.hdf5\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.28634 to 0.28421, saving model to ./model/best092-0.2842.hdf5\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.28421 to 0.28165, saving model to ./model/best093-0.2817.hdf5\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.28165 to 0.27930, saving model to ./model/best094-0.2793.hdf5\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.27930 to 0.27760, saving model to ./model/best095-0.2776.hdf5\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.27760 to 0.27672, saving model to ./model/best096-0.2767.hdf5\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.27672 to 0.27654, saving model to ./model/best097-0.2765.hdf5\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.27654\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.27654\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.27654 to 0.27614, saving model to ./model/best100-0.2761.hdf5\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.27614 to 0.27500, saving model to ./model/best101-0.2750.hdf5\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.27500 to 0.27343, saving model to ./model/best102-0.2734.hdf5\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.27343 to 0.27177, saving model to ./model/best103-0.2718.hdf5\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.27177 to 0.27039, saving model to ./model/best104-0.2704.hdf5\n",
      "\n",
      "Epoch 00105: val_loss improved from 0.27039 to 0.26953, saving model to ./model/best105-0.2695.hdf5\n",
      "\n",
      "Epoch 00106: val_loss improved from 0.26953 to 0.26919, saving model to ./model/best106-0.2692.hdf5\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.26919\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.26919\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.26919\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.26919 to 0.26858, saving model to ./model/best110-0.2686.hdf5\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.26858 to 0.26744, saving model to ./model/best111-0.2674.hdf5\n",
      "\n",
      "Epoch 00112: val_loss improved from 0.26744 to 0.26614, saving model to ./model/best112-0.2661.hdf5\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.26614 to 0.26499, saving model to ./model/best113-0.2650.hdf5\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.26499 to 0.26426, saving model to ./model/best114-0.2643.hdf5\n",
      "\n",
      "Epoch 00115: val_loss improved from 0.26426 to 0.26391, saving model to ./model/best115-0.2639.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00116: val_loss improved from 0.26391 to 0.26382, saving model to ./model/best116-0.2638.hdf5\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.26382 to 0.26374, saving model to ./model/best117-0.2637.hdf5\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.26374 to 0.26346, saving model to ./model/best118-0.2635.hdf5\n",
      "\n",
      "Epoch 00119: val_loss improved from 0.26346 to 0.26290, saving model to ./model/best119-0.2629.hdf5\n",
      "\n",
      "Epoch 00120: val_loss improved from 0.26290 to 0.26207, saving model to ./model/best120-0.2621.hdf5\n",
      "\n",
      "Epoch 00121: val_loss improved from 0.26207 to 0.26114, saving model to ./model/best121-0.2611.hdf5\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.26114 to 0.26032, saving model to ./model/best122-0.2603.hdf5\n",
      "\n",
      "Epoch 00123: val_loss improved from 0.26032 to 0.25976, saving model to ./model/best123-0.2598.hdf5\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.25976 to 0.25948, saving model to ./model/best124-0.2595.hdf5\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.25948 to 0.25945, saving model to ./model/best125-0.2594.hdf5\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.25945 to 0.25942, saving model to ./model/best126-0.2594.hdf5\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.25942 to 0.25925, saving model to ./model/best127-0.2593.hdf5\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.25925 to 0.25888, saving model to ./model/best128-0.2589.hdf5\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.25888 to 0.25834, saving model to ./model/best129-0.2583.hdf5\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.25834 to 0.25778, saving model to ./model/best130-0.2578.hdf5\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.25778 to 0.25733, saving model to ./model/best131-0.2573.hdf5\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.25733 to 0.25702, saving model to ./model/best132-0.2570.hdf5\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.25702 to 0.25675, saving model to ./model/best133-0.2568.hdf5\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.25675 to 0.25650, saving model to ./model/best134-0.2565.hdf5\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.25650 to 0.25621, saving model to ./model/best135-0.2562.hdf5\n",
      "\n",
      "Epoch 00136: val_loss improved from 0.25621 to 0.25586, saving model to ./model/best136-0.2559.hdf5\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.25586 to 0.25554, saving model to ./model/best137-0.2555.hdf5\n",
      "\n",
      "Epoch 00138: val_loss improved from 0.25554 to 0.25530, saving model to ./model/best138-0.2553.hdf5\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.25530 to 0.25514, saving model to ./model/best139-0.2551.hdf5\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.25514 to 0.25498, saving model to ./model/best140-0.2550.hdf5\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.25498 to 0.25476, saving model to ./model/best141-0.2548.hdf5\n",
      "\n",
      "Epoch 00142: val_loss improved from 0.25476 to 0.25457, saving model to ./model/best142-0.2546.hdf5\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.25457 to 0.25437, saving model to ./model/best143-0.2544.hdf5\n",
      "\n",
      "Epoch 00144: val_loss improved from 0.25437 to 0.25417, saving model to ./model/best144-0.2542.hdf5\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.25417 to 0.25391, saving model to ./model/best145-0.2539.hdf5\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.25391 to 0.25363, saving model to ./model/best146-0.2536.hdf5\n",
      "\n",
      "Epoch 00147: val_loss improved from 0.25363 to 0.25339, saving model to ./model/best147-0.2534.hdf5\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.25339 to 0.25322, saving model to ./model/best148-0.2532.hdf5\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.25322 to 0.25312, saving model to ./model/best149-0.2531.hdf5\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.25312 to 0.25305, saving model to ./model/best150-0.2530.hdf5\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.25305 to 0.25300, saving model to ./model/best151-0.2530.hdf5\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.25300 to 0.25297, saving model to ./model/best152-0.2530.hdf5\n",
      "\n",
      "Epoch 00153: val_loss improved from 0.25297 to 0.25294, saving model to ./model/best153-0.2529.hdf5\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.25294 to 0.25289, saving model to ./model/best154-0.2529.hdf5\n",
      "\n",
      "Epoch 00155: val_loss improved from 0.25289 to 0.25279, saving model to ./model/best155-0.2528.hdf5\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.25279 to 0.25269, saving model to ./model/best156-0.2527.hdf5\n",
      "\n",
      "Epoch 00157: val_loss improved from 0.25269 to 0.25262, saving model to ./model/best157-0.2526.hdf5\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.25262 to 0.25259, saving model to ./model/best158-0.2526.hdf5\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.25259\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.25259\n",
      "\n",
      "Epoch 00161: val_loss improved from 0.25259 to 0.25255, saving model to ./model/best161-0.2525.hdf5\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.25255 to 0.25241, saving model to ./model/best162-0.2524.hdf5\n",
      "\n",
      "Epoch 00163: val_loss improved from 0.25241 to 0.25227, saving model to ./model/best163-0.2523.hdf5\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.25227 to 0.25216, saving model to ./model/best164-0.2522.hdf5\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.25216 to 0.25208, saving model to ./model/best165-0.2521.hdf5\n",
      "\n",
      "Epoch 00166: val_loss improved from 0.25208 to 0.25201, saving model to ./model/best166-0.2520.hdf5\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.25201 to 0.25193, saving model to ./model/best167-0.2519.hdf5\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.25193 to 0.25181, saving model to ./model/best168-0.2518.hdf5\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.25181 to 0.25171, saving model to ./model/best169-0.2517.hdf5\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.25171 to 0.25163, saving model to ./model/best170-0.2516.hdf5\n",
      "\n",
      "Epoch 00171: val_loss improved from 0.25163 to 0.25157, saving model to ./model/best171-0.2516.hdf5\n",
      "\n",
      "Epoch 00172: val_loss improved from 0.25157 to 0.25153, saving model to ./model/best172-0.2515.hdf5\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.25153 to 0.25148, saving model to ./model/best173-0.2515.hdf5\n",
      "\n",
      "Epoch 00174: val_loss improved from 0.25148 to 0.25135, saving model to ./model/best174-0.2513.hdf5\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.25135 to 0.25125, saving model to ./model/best175-0.2513.hdf5\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.25125 to 0.25123, saving model to ./model/best176-0.2512.hdf5\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.25123\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.25123\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.25123\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.25123 to 0.25118, saving model to ./model/best180-0.2512.hdf5\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.25118 to 0.25105, saving model to ./model/best181-0.2511.hdf5\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.25105 to 0.25094, saving model to ./model/best182-0.2509.hdf5\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.25094 to 0.25089, saving model to ./model/best183-0.2509.hdf5\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.25089\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.25089\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.25089 to 0.25088, saving model to ./model/best186-0.2509.hdf5\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.25088 to 0.25078, saving model to ./model/best187-0.2508.hdf5\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.25078 to 0.25068, saving model to ./model/best188-0.2507.hdf5\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.25068 to 0.25058, saving model to ./model/best189-0.2506.hdf5\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.25058 to 0.25047, saving model to ./model/best190-0.2505.hdf5\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.25047 to 0.25032, saving model to ./model/best191-0.2503.hdf5\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.25032 to 0.25017, saving model to ./model/best192-0.2502.hdf5\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.25017 to 0.25005, saving model to ./model/best193-0.2500.hdf5\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.25005 to 0.24993, saving model to ./model/best194-0.2499.hdf5\n",
      "\n",
      "Epoch 00195: val_loss improved from 0.24993 to 0.24984, saving model to ./model/best195-0.2498.hdf5\n",
      "\n",
      "Epoch 00196: val_loss improved from 0.24984 to 0.24977, saving model to ./model/best196-0.2498.hdf5\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.24977 to 0.24966, saving model to ./model/best197-0.2497.hdf5\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.24966 to 0.24954, saving model to ./model/best198-0.2495.hdf5\n",
      "\n",
      "Epoch 00199: val_loss improved from 0.24954 to 0.24943, saving model to ./model/best199-0.2494.hdf5\n",
      "\n",
      "Epoch 00200: val_loss improved from 0.24943 to 0.24941, saving model to ./model/best200-0.2494.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00201: val_loss improved from 0.24941 to 0.24938, saving model to ./model/best201-0.2494.hdf5\n",
      "\n",
      "Epoch 00202: val_loss improved from 0.24938 to 0.24926, saving model to ./model/best202-0.2493.hdf5\n",
      "\n",
      "Epoch 00203: val_loss improved from 0.24926 to 0.24907, saving model to ./model/best203-0.2491.hdf5\n",
      "\n",
      "Epoch 00204: val_loss improved from 0.24907 to 0.24889, saving model to ./model/best204-0.2489.hdf5\n",
      "\n",
      "Epoch 00205: val_loss improved from 0.24889 to 0.24886, saving model to ./model/best205-0.2489.hdf5\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.24886\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.24886\n",
      "\n",
      "Epoch 00208: val_loss improved from 0.24886 to 0.24875, saving model to ./model/best208-0.2488.hdf5\n",
      "\n",
      "Epoch 00209: val_loss improved from 0.24875 to 0.24859, saving model to ./model/best209-0.2486.hdf5\n",
      "\n",
      "Epoch 00210: val_loss improved from 0.24859 to 0.24848, saving model to ./model/best210-0.2485.hdf5\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.24848 to 0.24839, saving model to ./model/best211-0.2484.hdf5\n",
      "\n",
      "Epoch 00212: val_loss improved from 0.24839 to 0.24829, saving model to ./model/best212-0.2483.hdf5\n",
      "\n",
      "Epoch 00213: val_loss improved from 0.24829 to 0.24819, saving model to ./model/best213-0.2482.hdf5\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.24819\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.24819\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.24819\n",
      "\n",
      "Epoch 00217: val_loss improved from 0.24819 to 0.24819, saving model to ./model/best217-0.2482.hdf5\n",
      "\n",
      "Epoch 00218: val_loss improved from 0.24819 to 0.24802, saving model to ./model/best218-0.2480.hdf5\n",
      "\n",
      "Epoch 00219: val_loss improved from 0.24802 to 0.24785, saving model to ./model/best219-0.2479.hdf5\n",
      "\n",
      "Epoch 00220: val_loss improved from 0.24785 to 0.24776, saving model to ./model/best220-0.2478.hdf5\n",
      "\n",
      "Epoch 00221: val_loss improved from 0.24776 to 0.24772, saving model to ./model/best221-0.2477.hdf5\n",
      "\n",
      "Epoch 00222: val_loss improved from 0.24772 to 0.24770, saving model to ./model/best222-0.2477.hdf5\n",
      "\n",
      "Epoch 00223: val_loss improved from 0.24770 to 0.24767, saving model to ./model/best223-0.2477.hdf5\n",
      "\n",
      "Epoch 00224: val_loss improved from 0.24767 to 0.24767, saving model to ./model/best224-0.2477.hdf5\n",
      "\n",
      "Epoch 00225: val_loss improved from 0.24767 to 0.24762, saving model to ./model/best225-0.2476.hdf5\n",
      "\n",
      "Epoch 00226: val_loss improved from 0.24762 to 0.24754, saving model to ./model/best226-0.2475.hdf5\n",
      "\n",
      "Epoch 00227: val_loss improved from 0.24754 to 0.24745, saving model to ./model/best227-0.2474.hdf5\n",
      "\n",
      "Epoch 00228: val_loss improved from 0.24745 to 0.24739, saving model to ./model/best228-0.2474.hdf5\n",
      "\n",
      "Epoch 00229: val_loss improved from 0.24739 to 0.24731, saving model to ./model/best229-0.2473.hdf5\n",
      "\n",
      "Epoch 00230: val_loss improved from 0.24731 to 0.24720, saving model to ./model/best230-0.2472.hdf5\n",
      "\n",
      "Epoch 00231: val_loss improved from 0.24720 to 0.24715, saving model to ./model/best231-0.2471.hdf5\n",
      "\n",
      "Epoch 00232: val_loss improved from 0.24715 to 0.24710, saving model to ./model/best232-0.2471.hdf5\n",
      "\n",
      "Epoch 00233: val_loss improved from 0.24710 to 0.24706, saving model to ./model/best233-0.2471.hdf5\n",
      "\n",
      "Epoch 00234: val_loss improved from 0.24706 to 0.24703, saving model to ./model/best234-0.2470.hdf5\n",
      "\n",
      "Epoch 00235: val_loss improved from 0.24703 to 0.24700, saving model to ./model/best235-0.2470.hdf5\n",
      "\n",
      "Epoch 00236: val_loss improved from 0.24700 to 0.24693, saving model to ./model/best236-0.2469.hdf5\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.24693 to 0.24679, saving model to ./model/best237-0.2468.hdf5\n",
      "\n",
      "Epoch 00238: val_loss improved from 0.24679 to 0.24659, saving model to ./model/best238-0.2466.hdf5\n",
      "\n",
      "Epoch 00239: val_loss improved from 0.24659 to 0.24639, saving model to ./model/best239-0.2464.hdf5\n",
      "\n",
      "Epoch 00240: val_loss improved from 0.24639 to 0.24627, saving model to ./model/best240-0.2463.hdf5\n",
      "\n",
      "Epoch 00241: val_loss improved from 0.24627 to 0.24625, saving model to ./model/best241-0.2463.hdf5\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.24625 to 0.24625, saving model to ./model/best242-0.2463.hdf5\n",
      "\n",
      "Epoch 00243: val_loss improved from 0.24625 to 0.24625, saving model to ./model/best243-0.2462.hdf5\n",
      "\n",
      "Epoch 00244: val_loss improved from 0.24625 to 0.24616, saving model to ./model/best244-0.2462.hdf5\n",
      "\n",
      "Epoch 00245: val_loss improved from 0.24616 to 0.24601, saving model to ./model/best245-0.2460.hdf5\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.24601 to 0.24583, saving model to ./model/best246-0.2458.hdf5\n",
      "\n",
      "Epoch 00247: val_loss improved from 0.24583 to 0.24564, saving model to ./model/best247-0.2456.hdf5\n",
      "\n",
      "Epoch 00248: val_loss improved from 0.24564 to 0.24547, saving model to ./model/best248-0.2455.hdf5\n",
      "\n",
      "Epoch 00249: val_loss improved from 0.24547 to 0.24529, saving model to ./model/best249-0.2453.hdf5\n",
      "\n",
      "Epoch 00250: val_loss improved from 0.24529 to 0.24520, saving model to ./model/best250-0.2452.hdf5\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.24520\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.24520\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.24520\n",
      "\n",
      "Epoch 00254: val_loss improved from 0.24520 to 0.24516, saving model to ./model/best254-0.2452.hdf5\n",
      "\n",
      "Epoch 00255: val_loss improved from 0.24516 to 0.24501, saving model to ./model/best255-0.2450.hdf5\n",
      "\n",
      "Epoch 00256: val_loss improved from 0.24501 to 0.24482, saving model to ./model/best256-0.2448.hdf5\n",
      "\n",
      "Epoch 00257: val_loss improved from 0.24482 to 0.24467, saving model to ./model/best257-0.2447.hdf5\n",
      "\n",
      "Epoch 00258: val_loss improved from 0.24467 to 0.24456, saving model to ./model/best258-0.2446.hdf5\n",
      "\n",
      "Epoch 00259: val_loss improved from 0.24456 to 0.24445, saving model to ./model/best259-0.2445.hdf5\n",
      "\n",
      "Epoch 00260: val_loss improved from 0.24445 to 0.24428, saving model to ./model/best260-0.2443.hdf5\n",
      "\n",
      "Epoch 00261: val_loss improved from 0.24428 to 0.24415, saving model to ./model/best261-0.2442.hdf5\n",
      "\n",
      "Epoch 00262: val_loss improved from 0.24415 to 0.24406, saving model to ./model/best262-0.2441.hdf5\n",
      "\n",
      "Epoch 00263: val_loss improved from 0.24406 to 0.24402, saving model to ./model/best263-0.2440.hdf5\n",
      "\n",
      "Epoch 00264: val_loss improved from 0.24402 to 0.24398, saving model to ./model/best264-0.2440.hdf5\n",
      "\n",
      "Epoch 00265: val_loss improved from 0.24398 to 0.24390, saving model to ./model/best265-0.2439.hdf5\n",
      "\n",
      "Epoch 00266: val_loss improved from 0.24390 to 0.24375, saving model to ./model/best266-0.2438.hdf5\n",
      "\n",
      "Epoch 00267: val_loss improved from 0.24375 to 0.24356, saving model to ./model/best267-0.2436.hdf5\n",
      "\n",
      "Epoch 00268: val_loss improved from 0.24356 to 0.24337, saving model to ./model/best268-0.2434.hdf5\n",
      "\n",
      "Epoch 00269: val_loss improved from 0.24337 to 0.24321, saving model to ./model/best269-0.2432.hdf5\n",
      "\n",
      "Epoch 00270: val_loss improved from 0.24321 to 0.24312, saving model to ./model/best270-0.2431.hdf5\n",
      "\n",
      "Epoch 00271: val_loss improved from 0.24312 to 0.24307, saving model to ./model/best271-0.2431.hdf5\n",
      "\n",
      "Epoch 00272: val_loss improved from 0.24307 to 0.24302, saving model to ./model/best272-0.2430.hdf5\n",
      "\n",
      "Epoch 00273: val_loss improved from 0.24302 to 0.24293, saving model to ./model/best273-0.2429.hdf5\n",
      "\n",
      "Epoch 00274: val_loss improved from 0.24293 to 0.24278, saving model to ./model/best274-0.2428.hdf5\n",
      "\n",
      "Epoch 00275: val_loss improved from 0.24278 to 0.24260, saving model to ./model/best275-0.2426.hdf5\n",
      "\n",
      "Epoch 00276: val_loss improved from 0.24260 to 0.24248, saving model to ./model/best276-0.2425.hdf5\n",
      "\n",
      "Epoch 00277: val_loss improved from 0.24248 to 0.24238, saving model to ./model/best277-0.2424.hdf5\n",
      "\n",
      "Epoch 00278: val_loss improved from 0.24238 to 0.24227, saving model to ./model/best278-0.2423.hdf5\n",
      "\n",
      "Epoch 00279: val_loss improved from 0.24227 to 0.24215, saving model to ./model/best279-0.2422.hdf5\n",
      "\n",
      "Epoch 00280: val_loss improved from 0.24215 to 0.24203, saving model to ./model/best280-0.2420.hdf5\n",
      "\n",
      "Epoch 00281: val_loss improved from 0.24203 to 0.24189, saving model to ./model/best281-0.2419.hdf5\n",
      "\n",
      "Epoch 00282: val_loss improved from 0.24189 to 0.24174, saving model to ./model/best282-0.2417.hdf5\n",
      "\n",
      "Epoch 00283: val_loss improved from 0.24174 to 0.24159, saving model to ./model/best283-0.2416.hdf5\n",
      "\n",
      "Epoch 00284: val_loss improved from 0.24159 to 0.24146, saving model to ./model/best284-0.2415.hdf5\n",
      "\n",
      "Epoch 00285: val_loss improved from 0.24146 to 0.24136, saving model to ./model/best285-0.2414.hdf5\n",
      "\n",
      "Epoch 00286: val_loss improved from 0.24136 to 0.24127, saving model to ./model/best286-0.2413.hdf5\n",
      "\n",
      "Epoch 00287: val_loss improved from 0.24127 to 0.24115, saving model to ./model/best287-0.2412.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00288: val_loss improved from 0.24115 to 0.24099, saving model to ./model/best288-0.2410.hdf5\n",
      "\n",
      "Epoch 00289: val_loss improved from 0.24099 to 0.24080, saving model to ./model/best289-0.2408.hdf5\n",
      "\n",
      "Epoch 00290: val_loss improved from 0.24080 to 0.24062, saving model to ./model/best290-0.2406.hdf5\n",
      "\n",
      "Epoch 00291: val_loss improved from 0.24062 to 0.24041, saving model to ./model/best291-0.2404.hdf5\n",
      "\n",
      "Epoch 00292: val_loss improved from 0.24041 to 0.24031, saving model to ./model/best292-0.2403.hdf5\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.24031\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.24031\n",
      "\n",
      "Epoch 00295: val_loss improved from 0.24031 to 0.24014, saving model to ./model/best295-0.2401.hdf5\n",
      "\n",
      "Epoch 00296: val_loss improved from 0.24014 to 0.23975, saving model to ./model/best296-0.2398.hdf5\n",
      "\n",
      "Epoch 00297: val_loss improved from 0.23975 to 0.23953, saving model to ./model/best297-0.2395.hdf5\n",
      "\n",
      "Epoch 00298: val_loss improved from 0.23953 to 0.23952, saving model to ./model/best298-0.2395.hdf5\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.23952\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.23952 to 0.23936, saving model to ./model/best300-0.2394.hdf5\n",
      "\n",
      "Epoch 00301: val_loss improved from 0.23936 to 0.23915, saving model to ./model/best301-0.2392.hdf5\n",
      "\n",
      "Epoch 00302: val_loss improved from 0.23915 to 0.23906, saving model to ./model/best302-0.2391.hdf5\n",
      "\n",
      "Epoch 00303: val_loss improved from 0.23906 to 0.23902, saving model to ./model/best303-0.2390.hdf5\n",
      "\n",
      "Epoch 00304: val_loss improved from 0.23902 to 0.23888, saving model to ./model/best304-0.2389.hdf5\n",
      "\n",
      "Epoch 00305: val_loss improved from 0.23888 to 0.23851, saving model to ./model/best305-0.2385.hdf5\n",
      "\n",
      "Epoch 00306: val_loss improved from 0.23851 to 0.23806, saving model to ./model/best306-0.2381.hdf5\n",
      "\n",
      "Epoch 00307: val_loss improved from 0.23806 to 0.23778, saving model to ./model/best307-0.2378.hdf5\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.23778\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 0.23778\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.23778\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.23778\n",
      "\n",
      "Epoch 00312: val_loss improved from 0.23778 to 0.23730, saving model to ./model/best312-0.2373.hdf5\n",
      "\n",
      "Epoch 00313: val_loss improved from 0.23730 to 0.23695, saving model to ./model/best313-0.2369.hdf5\n",
      "\n",
      "Epoch 00314: val_loss improved from 0.23695 to 0.23692, saving model to ./model/best314-0.2369.hdf5\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.23692\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 0.23692\n",
      "\n",
      "Epoch 00317: val_loss improved from 0.23692 to 0.23678, saving model to ./model/best317-0.2368.hdf5\n",
      "\n",
      "Epoch 00318: val_loss improved from 0.23678 to 0.23643, saving model to ./model/best318-0.2364.hdf5\n",
      "\n",
      "Epoch 00319: val_loss improved from 0.23643 to 0.23617, saving model to ./model/best319-0.2362.hdf5\n",
      "\n",
      "Epoch 00320: val_loss improved from 0.23617 to 0.23608, saving model to ./model/best320-0.2361.hdf5\n",
      "\n",
      "Epoch 00321: val_loss improved from 0.23608 to 0.23607, saving model to ./model/best321-0.2361.hdf5\n",
      "\n",
      "Epoch 00322: val_loss improved from 0.23607 to 0.23598, saving model to ./model/best322-0.2360.hdf5\n",
      "\n",
      "Epoch 00323: val_loss improved from 0.23598 to 0.23567, saving model to ./model/best323-0.2357.hdf5\n",
      "\n",
      "Epoch 00324: val_loss improved from 0.23567 to 0.23537, saving model to ./model/best324-0.2354.hdf5\n",
      "\n",
      "Epoch 00325: val_loss improved from 0.23537 to 0.23520, saving model to ./model/best325-0.2352.hdf5\n",
      "\n",
      "Epoch 00326: val_loss improved from 0.23520 to 0.23513, saving model to ./model/best326-0.2351.hdf5\n",
      "\n",
      "Epoch 00327: val_loss improved from 0.23513 to 0.23508, saving model to ./model/best327-0.2351.hdf5\n",
      "\n",
      "Epoch 00328: val_loss improved from 0.23508 to 0.23500, saving model to ./model/best328-0.2350.hdf5\n",
      "\n",
      "Epoch 00329: val_loss improved from 0.23500 to 0.23481, saving model to ./model/best329-0.2348.hdf5\n",
      "\n",
      "Epoch 00330: val_loss improved from 0.23481 to 0.23452, saving model to ./model/best330-0.2345.hdf5\n",
      "\n",
      "Epoch 00331: val_loss improved from 0.23452 to 0.23417, saving model to ./model/best331-0.2342.hdf5\n",
      "\n",
      "Epoch 00332: val_loss improved from 0.23417 to 0.23405, saving model to ./model/best332-0.2340.hdf5\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.23405\n",
      "\n",
      "Epoch 00334: val_loss improved from 0.23405 to 0.23405, saving model to ./model/best334-0.2340.hdf5\n",
      "\n",
      "Epoch 00335: val_loss improved from 0.23405 to 0.23380, saving model to ./model/best335-0.2338.hdf5\n",
      "\n",
      "Epoch 00336: val_loss improved from 0.23380 to 0.23356, saving model to ./model/best336-0.2336.hdf5\n",
      "\n",
      "Epoch 00337: val_loss improved from 0.23356 to 0.23339, saving model to ./model/best337-0.2334.hdf5\n",
      "\n",
      "Epoch 00338: val_loss improved from 0.23339 to 0.23321, saving model to ./model/best338-0.2332.hdf5\n",
      "\n",
      "Epoch 00339: val_loss improved from 0.23321 to 0.23296, saving model to ./model/best339-0.2330.hdf5\n",
      "\n",
      "Epoch 00340: val_loss improved from 0.23296 to 0.23278, saving model to ./model/best340-0.2328.hdf5\n",
      "\n",
      "Epoch 00341: val_loss improved from 0.23278 to 0.23276, saving model to ./model/best341-0.2328.hdf5\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.23276\n",
      "\n",
      "Epoch 00343: val_loss improved from 0.23276 to 0.23274, saving model to ./model/best343-0.2327.hdf5\n",
      "\n",
      "Epoch 00344: val_loss improved from 0.23274 to 0.23240, saving model to ./model/best344-0.2324.hdf5\n",
      "\n",
      "Epoch 00345: val_loss improved from 0.23240 to 0.23193, saving model to ./model/best345-0.2319.hdf5\n",
      "\n",
      "Epoch 00346: val_loss improved from 0.23193 to 0.23156, saving model to ./model/best346-0.2316.hdf5\n",
      "\n",
      "Epoch 00347: val_loss improved from 0.23156 to 0.23147, saving model to ./model/best347-0.2315.hdf5\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.23147\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.23147\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.23147\n",
      "\n",
      "Epoch 00351: val_loss improved from 0.23147 to 0.23128, saving model to ./model/best351-0.2313.hdf5\n",
      "\n",
      "Epoch 00352: val_loss improved from 0.23128 to 0.23080, saving model to ./model/best352-0.2308.hdf5\n",
      "\n",
      "Epoch 00353: val_loss improved from 0.23080 to 0.23065, saving model to ./model/best353-0.2307.hdf5\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.23065\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.23065\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.23065\n",
      "\n",
      "Epoch 00357: val_loss improved from 0.23065 to 0.23049, saving model to ./model/best357-0.2305.hdf5\n",
      "\n",
      "Epoch 00358: val_loss improved from 0.23049 to 0.22998, saving model to ./model/best358-0.2300.hdf5\n",
      "\n",
      "Epoch 00359: val_loss improved from 0.22998 to 0.22964, saving model to ./model/best359-0.2296.hdf5\n",
      "\n",
      "Epoch 00360: val_loss improved from 0.22964 to 0.22959, saving model to ./model/best360-0.2296.hdf5\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.22959\n",
      "\n",
      "Epoch 00362: val_loss improved from 0.22959 to 0.22951, saving model to ./model/best362-0.2295.hdf5\n",
      "\n",
      "Epoch 00363: val_loss improved from 0.22951 to 0.22930, saving model to ./model/best363-0.2293.hdf5\n",
      "\n",
      "Epoch 00364: val_loss improved from 0.22930 to 0.22916, saving model to ./model/best364-0.2292.hdf5\n",
      "\n",
      "Epoch 00365: val_loss improved from 0.22916 to 0.22905, saving model to ./model/best365-0.2290.hdf5\n",
      "\n",
      "Epoch 00366: val_loss improved from 0.22905 to 0.22887, saving model to ./model/best366-0.2289.hdf5\n",
      "\n",
      "Epoch 00367: val_loss improved from 0.22887 to 0.22846, saving model to ./model/best367-0.2285.hdf5\n",
      "\n",
      "Epoch 00368: val_loss improved from 0.22846 to 0.22800, saving model to ./model/best368-0.2280.hdf5\n",
      "\n",
      "Epoch 00369: val_loss improved from 0.22800 to 0.22773, saving model to ./model/best369-0.2277.hdf5\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 0.22773\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.22773\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.22773\n",
      "\n",
      "Epoch 00373: val_loss improved from 0.22773 to 0.22746, saving model to ./model/best373-0.2275.hdf5\n",
      "\n",
      "Epoch 00374: val_loss improved from 0.22746 to 0.22676, saving model to ./model/best374-0.2268.hdf5\n",
      "\n",
      "Epoch 00375: val_loss improved from 0.22676 to 0.22646, saving model to ./model/best375-0.2265.hdf5\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.22646\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.22646\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.22646\n",
      "\n",
      "Epoch 00379: val_loss improved from 0.22646 to 0.22617, saving model to ./model/best379-0.2262.hdf5\n",
      "\n",
      "Epoch 00380: val_loss improved from 0.22617 to 0.22574, saving model to ./model/best380-0.2257.hdf5\n",
      "\n",
      "Epoch 00381: val_loss improved from 0.22574 to 0.22562, saving model to ./model/best381-0.2256.hdf5\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.22562\n",
      "\n",
      "Epoch 00383: val_loss improved from 0.22562 to 0.22545, saving model to ./model/best383-0.2254.hdf5\n",
      "\n",
      "Epoch 00384: val_loss improved from 0.22545 to 0.22514, saving model to ./model/best384-0.2251.hdf5\n",
      "\n",
      "Epoch 00385: val_loss improved from 0.22514 to 0.22487, saving model to ./model/best385-0.2249.hdf5\n",
      "\n",
      "Epoch 00386: val_loss improved from 0.22487 to 0.22466, saving model to ./model/best386-0.2247.hdf5\n",
      "\n",
      "Epoch 00387: val_loss improved from 0.22466 to 0.22431, saving model to ./model/best387-0.2243.hdf5\n",
      "\n",
      "Epoch 00388: val_loss improved from 0.22431 to 0.22377, saving model to ./model/best388-0.2238.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00389: val_loss improved from 0.22377 to 0.22293, saving model to ./model/best389-0.2229.hdf5\n",
      "\n",
      "Epoch 00390: val_loss improved from 0.22293 to 0.22213, saving model to ./model/best390-0.2221.hdf5\n",
      "\n",
      "Epoch 00391: val_loss improved from 0.22213 to 0.22171, saving model to ./model/best391-0.2217.hdf5\n",
      "\n",
      "Epoch 00392: val_loss improved from 0.22171 to 0.22167, saving model to ./model/best392-0.2217.hdf5\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.22167\n",
      "\n",
      "Epoch 00394: val_loss improved from 0.22167 to 0.22158, saving model to ./model/best394-0.2216.hdf5\n",
      "\n",
      "Epoch 00395: val_loss improved from 0.22158 to 0.22133, saving model to ./model/best395-0.2213.hdf5\n",
      "\n",
      "Epoch 00396: val_loss improved from 0.22133 to 0.22116, saving model to ./model/best396-0.2212.hdf5\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.22116\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.22116\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.22116\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.22116\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.22116\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.22116\n",
      "\n",
      "Epoch 00403: val_loss improved from 0.22116 to 0.22104, saving model to ./model/best403-0.2210.hdf5\n",
      "\n",
      "Epoch 00404: val_loss improved from 0.22104 to 0.22047, saving model to ./model/best404-0.2205.hdf5\n",
      "\n",
      "Epoch 00405: val_loss improved from 0.22047 to 0.21988, saving model to ./model/best405-0.2199.hdf5\n",
      "\n",
      "Epoch 00406: val_loss improved from 0.21988 to 0.21935, saving model to ./model/best406-0.2194.hdf5\n",
      "\n",
      "Epoch 00407: val_loss improved from 0.21935 to 0.21905, saving model to ./model/best407-0.2190.hdf5\n",
      "\n",
      "Epoch 00408: val_loss improved from 0.21905 to 0.21896, saving model to ./model/best408-0.2190.hdf5\n",
      "\n",
      "Epoch 00409: val_loss improved from 0.21896 to 0.21893, saving model to ./model/best409-0.2189.hdf5\n",
      "\n",
      "Epoch 00410: val_loss improved from 0.21893 to 0.21881, saving model to ./model/best410-0.2188.hdf5\n",
      "\n",
      "Epoch 00411: val_loss improved from 0.21881 to 0.21852, saving model to ./model/best411-0.2185.hdf5\n",
      "\n",
      "Epoch 00412: val_loss improved from 0.21852 to 0.21816, saving model to ./model/best412-0.2182.hdf5\n",
      "\n",
      "Epoch 00413: val_loss improved from 0.21816 to 0.21778, saving model to ./model/best413-0.2178.hdf5\n",
      "\n",
      "Epoch 00414: val_loss improved from 0.21778 to 0.21763, saving model to ./model/best414-0.2176.hdf5\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.21763\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.21763\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.21763\n",
      "\n",
      "Epoch 00418: val_loss improved from 0.21763 to 0.21711, saving model to ./model/best418-0.2171.hdf5\n",
      "\n",
      "Epoch 00419: val_loss improved from 0.21711 to 0.21617, saving model to ./model/best419-0.2162.hdf5\n",
      "\n",
      "Epoch 00420: val_loss improved from 0.21617 to 0.21558, saving model to ./model/best420-0.2156.hdf5\n",
      "\n",
      "Epoch 00421: val_loss improved from 0.21558 to 0.21556, saving model to ./model/best421-0.2156.hdf5\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.21556\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.21556\n",
      "\n",
      "Epoch 00424: val_loss improved from 0.21556 to 0.21552, saving model to ./model/best424-0.2155.hdf5\n",
      "\n",
      "Epoch 00425: val_loss improved from 0.21552 to 0.21509, saving model to ./model/best425-0.2151.hdf5\n",
      "\n",
      "Epoch 00426: val_loss improved from 0.21509 to 0.21477, saving model to ./model/best426-0.2148.hdf5\n",
      "\n",
      "Epoch 00427: val_loss improved from 0.21477 to 0.21461, saving model to ./model/best427-0.2146.hdf5\n",
      "\n",
      "Epoch 00428: val_loss improved from 0.21461 to 0.21446, saving model to ./model/best428-0.2145.hdf5\n",
      "\n",
      "Epoch 00429: val_loss improved from 0.21446 to 0.21413, saving model to ./model/best429-0.2141.hdf5\n",
      "\n",
      "Epoch 00430: val_loss improved from 0.21413 to 0.21353, saving model to ./model/best430-0.2135.hdf5\n",
      "\n",
      "Epoch 00431: val_loss improved from 0.21353 to 0.21315, saving model to ./model/best431-0.2132.hdf5\n",
      "\n",
      "Epoch 00432: val_loss improved from 0.21315 to 0.21310, saving model to ./model/best432-0.2131.hdf5\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.21310\n",
      "\n",
      "Epoch 00434: val_loss improved from 0.21310 to 0.21309, saving model to ./model/best434-0.2131.hdf5\n",
      "\n",
      "Epoch 00435: val_loss improved from 0.21309 to 0.21276, saving model to ./model/best435-0.2128.hdf5\n",
      "\n",
      "Epoch 00436: val_loss improved from 0.21276 to 0.21227, saving model to ./model/best436-0.2123.hdf5\n",
      "\n",
      "Epoch 00437: val_loss improved from 0.21227 to 0.21190, saving model to ./model/best437-0.2119.hdf5\n",
      "\n",
      "Epoch 00438: val_loss improved from 0.21190 to 0.21184, saving model to ./model/best438-0.2118.hdf5\n",
      "\n",
      "Epoch 00439: val_loss improved from 0.21184 to 0.21166, saving model to ./model/best439-0.2117.hdf5\n",
      "\n",
      "Epoch 00440: val_loss improved from 0.21166 to 0.21127, saving model to ./model/best440-0.2113.hdf5\n",
      "\n",
      "Epoch 00441: val_loss improved from 0.21127 to 0.21082, saving model to ./model/best441-0.2108.hdf5\n",
      "\n",
      "Epoch 00442: val_loss improved from 0.21082 to 0.21059, saving model to ./model/best442-0.2106.hdf5\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.21059\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.21059\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.21059\n",
      "\n",
      "Epoch 00446: val_loss improved from 0.21059 to 0.21007, saving model to ./model/best446-0.2101.hdf5\n",
      "\n",
      "Epoch 00447: val_loss improved from 0.21007 to 0.20926, saving model to ./model/best447-0.2093.hdf5\n",
      "\n",
      "Epoch 00448: val_loss improved from 0.20926 to 0.20878, saving model to ./model/best448-0.2088.hdf5\n",
      "\n",
      "Epoch 00449: val_loss improved from 0.20878 to 0.20865, saving model to ./model/best449-0.2086.hdf5\n",
      "\n",
      "Epoch 00450: val_loss improved from 0.20865 to 0.20854, saving model to ./model/best450-0.2085.hdf5\n",
      "\n",
      "Epoch 00451: val_loss improved from 0.20854 to 0.20815, saving model to ./model/best451-0.2082.hdf5\n",
      "\n",
      "Epoch 00452: val_loss improved from 0.20815 to 0.20750, saving model to ./model/best452-0.2075.hdf5\n",
      "\n",
      "Epoch 00453: val_loss improved from 0.20750 to 0.20684, saving model to ./model/best453-0.2068.hdf5\n",
      "\n",
      "Epoch 00454: val_loss improved from 0.20684 to 0.20649, saving model to ./model/best454-0.2065.hdf5\n",
      "\n",
      "Epoch 00455: val_loss improved from 0.20649 to 0.20638, saving model to ./model/best455-0.2064.hdf5\n",
      "\n",
      "Epoch 00456: val_loss improved from 0.20638 to 0.20622, saving model to ./model/best456-0.2062.hdf5\n",
      "\n",
      "Epoch 00457: val_loss improved from 0.20622 to 0.20585, saving model to ./model/best457-0.2059.hdf5\n",
      "\n",
      "Epoch 00458: val_loss improved from 0.20585 to 0.20536, saving model to ./model/best458-0.2054.hdf5\n",
      "\n",
      "Epoch 00459: val_loss improved from 0.20536 to 0.20501, saving model to ./model/best459-0.2050.hdf5\n",
      "\n",
      "Epoch 00460: val_loss improved from 0.20501 to 0.20489, saving model to ./model/best460-0.2049.hdf5\n",
      "\n",
      "Epoch 00461: val_loss improved from 0.20489 to 0.20486, saving model to ./model/best461-0.2049.hdf5\n",
      "\n",
      "Epoch 00462: val_loss improved from 0.20486 to 0.20470, saving model to ./model/best462-0.2047.hdf5\n",
      "\n",
      "Epoch 00463: val_loss improved from 0.20470 to 0.20446, saving model to ./model/best463-0.2045.hdf5\n",
      "\n",
      "Epoch 00464: val_loss improved from 0.20446 to 0.20424, saving model to ./model/best464-0.2042.hdf5\n",
      "\n",
      "Epoch 00465: val_loss improved from 0.20424 to 0.20417, saving model to ./model/best465-0.2042.hdf5\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.20417\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.20417\n",
      "\n",
      "Epoch 00468: val_loss improved from 0.20417 to 0.20402, saving model to ./model/best468-0.2040.hdf5\n",
      "\n",
      "Epoch 00469: val_loss improved from 0.20402 to 0.20372, saving model to ./model/best469-0.2037.hdf5\n",
      "\n",
      "Epoch 00470: val_loss improved from 0.20372 to 0.20351, saving model to ./model/best470-0.2035.hdf5\n",
      "\n",
      "Epoch 00471: val_loss improved from 0.20351 to 0.20339, saving model to ./model/best471-0.2034.hdf5\n",
      "\n",
      "Epoch 00472: val_loss improved from 0.20339 to 0.20326, saving model to ./model/best472-0.2033.hdf5\n",
      "\n",
      "Epoch 00473: val_loss improved from 0.20326 to 0.20303, saving model to ./model/best473-0.2030.hdf5\n",
      "\n",
      "Epoch 00474: val_loss improved from 0.20303 to 0.20276, saving model to ./model/best474-0.2028.hdf5\n",
      "\n",
      "Epoch 00475: val_loss improved from 0.20276 to 0.20253, saving model to ./model/best475-0.2025.hdf5\n",
      "\n",
      "Epoch 00476: val_loss improved from 0.20253 to 0.20231, saving model to ./model/best476-0.2023.hdf5\n",
      "\n",
      "Epoch 00477: val_loss improved from 0.20231 to 0.20224, saving model to ./model/best477-0.2022.hdf5\n",
      "\n",
      "Epoch 00478: val_loss improved from 0.20224 to 0.20216, saving model to ./model/best478-0.2022.hdf5\n",
      "\n",
      "Epoch 00479: val_loss improved from 0.20216 to 0.20195, saving model to ./model/best479-0.2019.hdf5\n",
      "\n",
      "Epoch 00480: val_loss improved from 0.20195 to 0.20167, saving model to ./model/best480-0.2017.hdf5\n",
      "\n",
      "Epoch 00481: val_loss improved from 0.20167 to 0.20127, saving model to ./model/best481-0.2013.hdf5\n",
      "\n",
      "Epoch 00482: val_loss improved from 0.20127 to 0.20084, saving model to ./model/best482-0.2008.hdf5\n",
      "\n",
      "Epoch 00483: val_loss improved from 0.20084 to 0.20043, saving model to ./model/best483-0.2004.hdf5\n",
      "\n",
      "Epoch 00484: val_loss improved from 0.20043 to 0.20011, saving model to ./model/best484-0.2001.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00485: val_loss improved from 0.20011 to 0.20007, saving model to ./model/best485-0.2001.hdf5\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.20007\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.20007\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.20007\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.20007\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.20007\n",
      "\n",
      "Epoch 00491: val_loss improved from 0.20007 to 0.19972, saving model to ./model/best491-0.1997.hdf5\n",
      "\n",
      "Epoch 00492: val_loss improved from 0.19972 to 0.19926, saving model to ./model/best492-0.1993.hdf5\n",
      "\n",
      "Epoch 00493: val_loss improved from 0.19926 to 0.19880, saving model to ./model/best493-0.1988.hdf5\n",
      "\n",
      "Epoch 00494: val_loss improved from 0.19880 to 0.19853, saving model to ./model/best494-0.1985.hdf5\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.19853\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.19853\n",
      "\n",
      "Epoch 00497: val_loss improved from 0.19853 to 0.19848, saving model to ./model/best497-0.1985.hdf5\n",
      "\n",
      "Epoch 00498: val_loss improved from 0.19848 to 0.19813, saving model to ./model/best498-0.1981.hdf5\n",
      "\n",
      "Epoch 00499: val_loss improved from 0.19813 to 0.19797, saving model to ./model/best499-0.1980.hdf5\n",
      "\n",
      "Epoch 00500: val_loss improved from 0.19797 to 0.19789, saving model to ./model/best500-0.1979.hdf5\n",
      "\n",
      "Epoch 00501: val_loss improved from 0.19789 to 0.19770, saving model to ./model/best501-0.1977.hdf5\n",
      "\n",
      "Epoch 00502: val_loss improved from 0.19770 to 0.19737, saving model to ./model/best502-0.1974.hdf5\n",
      "\n",
      "Epoch 00503: val_loss improved from 0.19737 to 0.19706, saving model to ./model/best503-0.1971.hdf5\n",
      "\n",
      "Epoch 00504: val_loss improved from 0.19706 to 0.19692, saving model to ./model/best504-0.1969.hdf5\n",
      "\n",
      "Epoch 00505: val_loss improved from 0.19692 to 0.19682, saving model to ./model/best505-0.1968.hdf5\n",
      "\n",
      "Epoch 00506: val_loss improved from 0.19682 to 0.19664, saving model to ./model/best506-0.1966.hdf5\n",
      "\n",
      "Epoch 00507: val_loss improved from 0.19664 to 0.19620, saving model to ./model/best507-0.1962.hdf5\n",
      "\n",
      "Epoch 00508: val_loss improved from 0.19620 to 0.19595, saving model to ./model/best508-0.1960.hdf5\n",
      "\n",
      "Epoch 00509: val_loss improved from 0.19595 to 0.19590, saving model to ./model/best509-0.1959.hdf5\n",
      "\n",
      "Epoch 00510: val_loss improved from 0.19590 to 0.19582, saving model to ./model/best510-0.1958.hdf5\n",
      "\n",
      "Epoch 00511: val_loss improved from 0.19582 to 0.19555, saving model to ./model/best511-0.1956.hdf5\n",
      "\n",
      "Epoch 00512: val_loss improved from 0.19555 to 0.19536, saving model to ./model/best512-0.1954.hdf5\n",
      "\n",
      "Epoch 00513: val_loss improved from 0.19536 to 0.19502, saving model to ./model/best513-0.1950.hdf5\n",
      "\n",
      "Epoch 00514: val_loss improved from 0.19502 to 0.19434, saving model to ./model/best514-0.1943.hdf5\n",
      "\n",
      "Epoch 00515: val_loss improved from 0.19434 to 0.19347, saving model to ./model/best515-0.1935.hdf5\n",
      "\n",
      "Epoch 00516: val_loss improved from 0.19347 to 0.19265, saving model to ./model/best516-0.1927.hdf5\n",
      "\n",
      "Epoch 00517: val_loss improved from 0.19265 to 0.19219, saving model to ./model/best517-0.1922.hdf5\n",
      "\n",
      "Epoch 00518: val_loss improved from 0.19219 to 0.19172, saving model to ./model/best518-0.1917.hdf5\n",
      "\n",
      "Epoch 00519: val_loss improved from 0.19172 to 0.19066, saving model to ./model/best519-0.1907.hdf5\n",
      "\n",
      "Epoch 00520: val_loss improved from 0.19066 to 0.18941, saving model to ./model/best520-0.1894.hdf5\n",
      "\n",
      "Epoch 00521: val_loss improved from 0.18941 to 0.18861, saving model to ./model/best521-0.1886.hdf5\n",
      "\n",
      "Epoch 00522: val_loss improved from 0.18861 to 0.18814, saving model to ./model/best522-0.1881.hdf5\n",
      "\n",
      "Epoch 00523: val_loss improved from 0.18814 to 0.18766, saving model to ./model/best523-0.1877.hdf5\n",
      "\n",
      "Epoch 00524: val_loss improved from 0.18766 to 0.18661, saving model to ./model/best524-0.1866.hdf5\n",
      "\n",
      "Epoch 00525: val_loss improved from 0.18661 to 0.18545, saving model to ./model/best525-0.1854.hdf5\n",
      "\n",
      "Epoch 00526: val_loss improved from 0.18545 to 0.18478, saving model to ./model/best526-0.1848.hdf5\n",
      "\n",
      "Epoch 00527: val_loss improved from 0.18478 to 0.18462, saving model to ./model/best527-0.1846.hdf5\n",
      "\n",
      "Epoch 00528: val_loss improved from 0.18462 to 0.18447, saving model to ./model/best528-0.1845.hdf5\n",
      "\n",
      "Epoch 00529: val_loss improved from 0.18447 to 0.18400, saving model to ./model/best529-0.1840.hdf5\n",
      "\n",
      "Epoch 00530: val_loss improved from 0.18400 to 0.18339, saving model to ./model/best530-0.1834.hdf5\n",
      "\n",
      "Epoch 00531: val_loss improved from 0.18339 to 0.18306, saving model to ./model/best531-0.1831.hdf5\n",
      "\n",
      "Epoch 00532: val_loss improved from 0.18306 to 0.18303, saving model to ./model/best532-0.1830.hdf5\n",
      "\n",
      "Epoch 00533: val_loss improved from 0.18303 to 0.18288, saving model to ./model/best533-0.1829.hdf5\n",
      "\n",
      "Epoch 00534: val_loss improved from 0.18288 to 0.18246, saving model to ./model/best534-0.1825.hdf5\n",
      "\n",
      "Epoch 00535: val_loss improved from 0.18246 to 0.18218, saving model to ./model/best535-0.1822.hdf5\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.18218\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.18218\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.18218\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.18218\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.18218\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.18218\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.18218\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.18218\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.18218\n",
      "\n",
      "Epoch 00545: val_loss improved from 0.18218 to 0.18207, saving model to ./model/best545-0.1821.hdf5\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.18207\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.18207\n",
      "\n",
      "Epoch 00548: val_loss improved from 0.18207 to 0.18171, saving model to ./model/best548-0.1817.hdf5\n",
      "\n",
      "Epoch 00549: val_loss improved from 0.18171 to 0.18128, saving model to ./model/best549-0.1813.hdf5\n",
      "\n",
      "Epoch 00550: val_loss improved from 0.18128 to 0.18125, saving model to ./model/best550-0.1813.hdf5\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.18125\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 0.18125\n",
      "\n",
      "Epoch 00553: val_loss improved from 0.18125 to 0.18087, saving model to ./model/best553-0.1809.hdf5\n",
      "\n",
      "Epoch 00554: val_loss improved from 0.18087 to 0.18045, saving model to ./model/best554-0.1804.hdf5\n",
      "\n",
      "Epoch 00555: val_loss improved from 0.18045 to 0.18025, saving model to ./model/best555-0.1802.hdf5\n",
      "\n",
      "Epoch 00556: val_loss improved from 0.18025 to 0.17991, saving model to ./model/best556-0.1799.hdf5\n",
      "\n",
      "Epoch 00557: val_loss improved from 0.17991 to 0.17947, saving model to ./model/best557-0.1795.hdf5\n",
      "\n",
      "Epoch 00558: val_loss improved from 0.17947 to 0.17918, saving model to ./model/best558-0.1792.hdf5\n",
      "\n",
      "Epoch 00559: val_loss improved from 0.17918 to 0.17912, saving model to ./model/best559-0.1791.hdf5\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.17912\n",
      "\n",
      "Epoch 00561: val_loss improved from 0.17912 to 0.17912, saving model to ./model/best561-0.1791.hdf5\n",
      "\n",
      "Epoch 00562: val_loss improved from 0.17912 to 0.17891, saving model to ./model/best562-0.1789.hdf5\n",
      "\n",
      "Epoch 00563: val_loss improved from 0.17891 to 0.17880, saving model to ./model/best563-0.1788.hdf5\n",
      "\n",
      "Epoch 00564: val_loss improved from 0.17880 to 0.17873, saving model to ./model/best564-0.1787.hdf5\n",
      "\n",
      "Epoch 00565: val_loss improved from 0.17873 to 0.17844, saving model to ./model/best565-0.1784.hdf5\n",
      "\n",
      "Epoch 00566: val_loss improved from 0.17844 to 0.17813, saving model to ./model/best566-0.1781.hdf5\n",
      "\n",
      "Epoch 00567: val_loss improved from 0.17813 to 0.17799, saving model to ./model/best567-0.1780.hdf5\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.17799\n",
      "\n",
      "Epoch 00569: val_loss improved from 0.17799 to 0.17794, saving model to ./model/best569-0.1779.hdf5\n",
      "\n",
      "Epoch 00570: val_loss improved from 0.17794 to 0.17773, saving model to ./model/best570-0.1777.hdf5\n",
      "\n",
      "Epoch 00571: val_loss improved from 0.17773 to 0.17756, saving model to ./model/best571-0.1776.hdf5\n",
      "\n",
      "Epoch 00572: val_loss improved from 0.17756 to 0.17751, saving model to ./model/best572-0.1775.hdf5\n",
      "\n",
      "Epoch 00573: val_loss improved from 0.17751 to 0.17743, saving model to ./model/best573-0.1774.hdf5\n",
      "\n",
      "Epoch 00574: val_loss improved from 0.17743 to 0.17720, saving model to ./model/best574-0.1772.hdf5\n",
      "\n",
      "Epoch 00575: val_loss improved from 0.17720 to 0.17690, saving model to ./model/best575-0.1769.hdf5\n",
      "\n",
      "Epoch 00576: val_loss improved from 0.17690 to 0.17674, saving model to ./model/best576-0.1767.hdf5\n",
      "\n",
      "Epoch 00577: val_loss improved from 0.17674 to 0.17657, saving model to ./model/best577-0.1766.hdf5\n",
      "\n",
      "Epoch 00578: val_loss improved from 0.17657 to 0.17634, saving model to ./model/best578-0.1763.hdf5\n",
      "\n",
      "Epoch 00579: val_loss improved from 0.17634 to 0.17619, saving model to ./model/best579-0.1762.hdf5\n",
      "\n",
      "Epoch 00580: val_loss improved from 0.17619 to 0.17606, saving model to ./model/best580-0.1761.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00581: val_loss improved from 0.17606 to 0.17590, saving model to ./model/best581-0.1759.hdf5\n",
      "\n",
      "Epoch 00582: val_loss improved from 0.17590 to 0.17571, saving model to ./model/best582-0.1757.hdf5\n",
      "\n",
      "Epoch 00583: val_loss improved from 0.17571 to 0.17554, saving model to ./model/best583-0.1755.hdf5\n",
      "\n",
      "Epoch 00584: val_loss improved from 0.17554 to 0.17541, saving model to ./model/best584-0.1754.hdf5\n",
      "\n",
      "Epoch 00585: val_loss improved from 0.17541 to 0.17526, saving model to ./model/best585-0.1753.hdf5\n",
      "\n",
      "Epoch 00586: val_loss improved from 0.17526 to 0.17505, saving model to ./model/best586-0.1750.hdf5\n",
      "\n",
      "Epoch 00587: val_loss improved from 0.17505 to 0.17493, saving model to ./model/best587-0.1749.hdf5\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.17493\n",
      "\n",
      "Epoch 00589: val_loss improved from 0.17493 to 0.17487, saving model to ./model/best589-0.1749.hdf5\n",
      "\n",
      "Epoch 00590: val_loss improved from 0.17487 to 0.17466, saving model to ./model/best590-0.1747.hdf5\n",
      "\n",
      "Epoch 00591: val_loss improved from 0.17466 to 0.17446, saving model to ./model/best591-0.1745.hdf5\n",
      "\n",
      "Epoch 00592: val_loss improved from 0.17446 to 0.17421, saving model to ./model/best592-0.1742.hdf5\n",
      "\n",
      "Epoch 00593: val_loss improved from 0.17421 to 0.17396, saving model to ./model/best593-0.1740.hdf5\n",
      "\n",
      "Epoch 00594: val_loss improved from 0.17396 to 0.17385, saving model to ./model/best594-0.1738.hdf5\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.17385\n",
      "\n",
      "Epoch 00596: val_loss improved from 0.17385 to 0.17378, saving model to ./model/best596-0.1738.hdf5\n",
      "\n",
      "Epoch 00597: val_loss improved from 0.17378 to 0.17351, saving model to ./model/best597-0.1735.hdf5\n",
      "\n",
      "Epoch 00598: val_loss improved from 0.17351 to 0.17334, saving model to ./model/best598-0.1733.hdf5\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.17334\n",
      "\n",
      "Epoch 00600: val_loss improved from 0.17334 to 0.17326, saving model to ./model/best600-0.1733.hdf5\n",
      "\n",
      "Epoch 00601: val_loss improved from 0.17326 to 0.17303, saving model to ./model/best601-0.1730.hdf5\n",
      "\n",
      "Epoch 00602: val_loss improved from 0.17303 to 0.17285, saving model to ./model/best602-0.1728.hdf5\n",
      "\n",
      "Epoch 00603: val_loss improved from 0.17285 to 0.17282, saving model to ./model/best603-0.1728.hdf5\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.17282\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.17282\n",
      "\n",
      "Epoch 00606: val_loss improved from 0.17282 to 0.17236, saving model to ./model/best606-0.1724.hdf5\n",
      "\n",
      "Epoch 00607: val_loss improved from 0.17236 to 0.17207, saving model to ./model/best607-0.1721.hdf5\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.17207\n",
      "\n",
      "Epoch 00609: val_loss improved from 0.17207 to 0.17177, saving model to ./model/best609-0.1718.hdf5\n",
      "\n",
      "Epoch 00610: val_loss improved from 0.17177 to 0.17111, saving model to ./model/best610-0.1711.hdf5\n",
      "\n",
      "Epoch 00611: val_loss improved from 0.17111 to 0.17096, saving model to ./model/best611-0.1710.hdf5\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.17096\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.17096\n",
      "\n",
      "Epoch 00614: val_loss improved from 0.17096 to 0.17068, saving model to ./model/best614-0.1707.hdf5\n",
      "\n",
      "Epoch 00615: val_loss improved from 0.17068 to 0.17066, saving model to ./model/best615-0.1707.hdf5\n",
      "\n",
      "Epoch 00616: val_loss improved from 0.17066 to 0.17066, saving model to ./model/best616-0.1707.hdf5\n",
      "\n",
      "Epoch 00617: val_loss improved from 0.17066 to 0.17051, saving model to ./model/best617-0.1705.hdf5\n",
      "\n",
      "Epoch 00618: val_loss improved from 0.17051 to 0.17035, saving model to ./model/best618-0.1704.hdf5\n",
      "\n",
      "Epoch 00619: val_loss improved from 0.17035 to 0.17035, saving model to ./model/best619-0.1704.hdf5\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.17035\n",
      "\n",
      "Epoch 00621: val_loss improved from 0.17035 to 0.17026, saving model to ./model/best621-0.1703.hdf5\n",
      "\n",
      "Epoch 00622: val_loss improved from 0.17026 to 0.17010, saving model to ./model/best622-0.1701.hdf5\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.17010\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.17010\n",
      "\n",
      "Epoch 00625: val_loss improved from 0.17010 to 0.16939, saving model to ./model/best625-0.1694.hdf5\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.16939\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.16939\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.16939\n",
      "\n",
      "Epoch 00629: val_loss improved from 0.16939 to 0.16906, saving model to ./model/best629-0.1691.hdf5\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.16906\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.16906\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.16906\n",
      "\n",
      "Epoch 00633: val_loss improved from 0.16906 to 0.16875, saving model to ./model/best633-0.1687.hdf5\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.16875\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.16875\n",
      "\n",
      "Epoch 00636: val_loss improved from 0.16875 to 0.16866, saving model to ./model/best636-0.1687.hdf5\n",
      "\n",
      "Epoch 00637: val_loss improved from 0.16866 to 0.16762, saving model to ./model/best637-0.1676.hdf5\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.16762\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.16762\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.16762\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.16762\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.16762\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.16762\n",
      "\n",
      "Epoch 00644: val_loss improved from 0.16762 to 0.16725, saving model to ./model/best644-0.1672.hdf5\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.16725\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.16725\n",
      "\n",
      "Epoch 00647: val_loss improved from 0.16725 to 0.16713, saving model to ./model/best647-0.1671.hdf5\n",
      "\n",
      "Epoch 00648: val_loss improved from 0.16713 to 0.16699, saving model to ./model/best648-0.1670.hdf5\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.16699\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.16699\n",
      "\n",
      "Epoch 00651: val_loss improved from 0.16699 to 0.16667, saving model to ./model/best651-0.1667.hdf5\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.16667\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.16667\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.16667\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.16667\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.16667\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.16667\n",
      "\n",
      "Epoch 00658: val_loss improved from 0.16667 to 0.16645, saving model to ./model/best658-0.1664.hdf5\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.16645\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.16645\n",
      "\n",
      "Epoch 00661: val_loss improved from 0.16645 to 0.16630, saving model to ./model/best661-0.1663.hdf5\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.16630\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.16630\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.16630\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.16630\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.16630\n",
      "\n",
      "Epoch 00667: val_loss improved from 0.16630 to 0.16543, saving model to ./model/best667-0.1654.hdf5\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.16543\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.16543\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.16543\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.16543\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.16543\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.16543\n",
      "\n",
      "Epoch 00674: val_loss improved from 0.16543 to 0.16524, saving model to ./model/best674-0.1652.hdf5\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.16524\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.16524\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.16524\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.16524\n",
      "\n",
      "Epoch 00679: val_loss improved from 0.16524 to 0.16513, saving model to ./model/best679-0.1651.hdf5\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.16513\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.16513\n",
      "\n",
      "Epoch 00682: val_loss improved from 0.16513 to 0.16500, saving model to ./model/best682-0.1650.hdf5\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.16500\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.16500\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.16500\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.16500\n",
      "\n",
      "Epoch 00687: val_loss improved from 0.16500 to 0.16500, saving model to ./model/best687-0.1650.hdf5\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.16500\n",
      "\n",
      "Epoch 00689: val_loss improved from 0.16500 to 0.16477, saving model to ./model/best689-0.1648.hdf5\n",
      "\n",
      "Epoch 00690: val_loss improved from 0.16477 to 0.16412, saving model to ./model/best690-0.1641.hdf5\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.16412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00692: val_loss did not improve from 0.16412\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.16412\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.16412\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.16412\n",
      "\n",
      "Epoch 00696: val_loss improved from 0.16412 to 0.16180, saving model to ./model/best696-0.1618.hdf5\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 0.16180\n",
      "\n",
      "Epoch 00720: val_loss improved from 0.16180 to 0.16150, saving model to ./model/best720-0.1615.hdf5\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 0.16150\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.16150\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.16150\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.16150\n",
      "\n",
      "Epoch 00725: val_loss improved from 0.16150 to 0.16123, saving model to ./model/best725-0.1612.hdf5\n",
      "\n",
      "Epoch 00726: val_loss improved from 0.16123 to 0.16114, saving model to ./model/best726-0.1611.hdf5\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.16114\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.16114\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.16114\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 0.16114\n",
      "\n",
      "Epoch 00731: val_loss improved from 0.16114 to 0.16054, saving model to ./model/best731-0.1605.hdf5\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.16054\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.16054\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.16054\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.16054\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.16054\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.16054\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.16054\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.16054\n",
      "\n",
      "Epoch 00740: val_loss improved from 0.16054 to 0.15991, saving model to ./model/best740-0.1599.hdf5\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.15991\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.15991\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 0.15991\n",
      "\n",
      "Epoch 00744: val_loss improved from 0.15991 to 0.15982, saving model to ./model/best744-0.1598.hdf5\n",
      "\n",
      "Epoch 00745: val_loss improved from 0.15982 to 0.15956, saving model to ./model/best745-0.1596.hdf5\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 0.15956\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.15956\n",
      "\n",
      "Epoch 00748: val_loss improved from 0.15956 to 0.15886, saving model to ./model/best748-0.1589.hdf5\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.15886\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.15886\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.15886\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.15886\n",
      "\n",
      "Epoch 00753: val_loss improved from 0.15886 to 0.15314, saving model to ./model/best753-0.1531.hdf5\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.15314\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 0.15314\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 0.15314\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.15314\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.15314\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.15314\n",
      "\n",
      "Epoch 00760: val_loss improved from 0.15314 to 0.15282, saving model to ./model/best760-0.1528.hdf5\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 0.15282\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 0.15282\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 0.15282\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 0.15282\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 0.15282\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 0.15282\n",
      "\n",
      "Epoch 00767: val_loss improved from 0.15282 to 0.15005, saving model to ./model/best767-0.1500.hdf5\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 0.15005\n",
      "\n",
      "Epoch 00840: val_loss improved from 0.15005 to 0.14886, saving model to ./model/best840-0.1489.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00841: val_loss did not improve from 0.14886\n",
      "\n",
      "Epoch 00842: val_loss improved from 0.14886 to 0.14593, saving model to ./model/best842-0.1459.hdf5\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 0.14593\n",
      "\n",
      "Epoch 00844: val_loss improved from 0.14593 to 0.14101, saving model to ./model/best844-0.1410.hdf5\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 0.14101\n",
      "\n",
      "Epoch 00846: val_loss improved from 0.14101 to 0.13456, saving model to ./model/best846-0.1346.hdf5\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 0.13456\n",
      "\n",
      "Epoch 00848: val_loss improved from 0.13456 to 0.13168, saving model to ./model/best848-0.1317.hdf5\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 0.13168\n",
      "\n",
      "Epoch 00917: val_loss improved from 0.13168 to 0.12237, saving model to ./model/best917-0.1224.hdf5\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 0.12237\n",
      "\n",
      "Epoch 00919: val_loss improved from 0.12237 to 0.11476, saving model to ./model/best919-0.1148.hdf5\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00984: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00985: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00986: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00989: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00992: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 01001: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 01002: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 01003: val_loss did not improve from 0.11476\n",
      "\n",
      "Epoch 01004: val_loss improved from 0.11476 to 0.11224, saving model to ./model/best1004-0.1122.hdf5\n",
      "\n",
      "Epoch 01005: val_loss did not improve from 0.11224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01006: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01007: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01008: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01009: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01010: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01011: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01012: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01013: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01014: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01015: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01016: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01017: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01018: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01019: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01020: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01021: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01022: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01023: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01024: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01025: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01026: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01027: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01028: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01029: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01030: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01031: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01032: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01033: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01034: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01035: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01036: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01037: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01038: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01039: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01040: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01041: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01042: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01043: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01044: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01045: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01046: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01047: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01048: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01049: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01050: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01051: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01052: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01053: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01054: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01055: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01056: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01057: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01058: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01059: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01060: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01061: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01062: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01063: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01064: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01065: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01066: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01067: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01068: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01069: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01070: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01071: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01072: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01073: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01074: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01075: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01076: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01077: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01078: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01079: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01080: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01081: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01082: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01083: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01084: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01085: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01086: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01087: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01088: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01089: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01090: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01091: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01092: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01093: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01094: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01095: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01096: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01097: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01098: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01099: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01100: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01101: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01102: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01103: val_loss did not improve from 0.11224\n",
      "\n",
      "Epoch 01104: val_loss did not improve from 0.11224\n"
     ]
    }
   ],
   "source": [
    "# 모델 실행 및 저장\n",
    "history = model.fit(X, Y, validation_split=0.2, epochs=3500, batch_size=500,\n",
    "                    verbose=0, callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1838번이 베스트, best1004-0.1122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 - 0s - loss: 0.0837 - accuracy: 0.9596\n",
      "\n",
      " Accuracy: 0.9596\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model/best1004-0.1122.hdf5')\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X, Y, verbose=2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss=history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc=history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x 값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.ylim(0,1)\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. load.digits - 다중분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = load_digits()\n",
    "df_pre2 = pd.DataFrame(di.data)\n",
    "df_pre2.head(20)\n",
    "\n",
    "X = di.data\n",
    "Y = di.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y)\n",
    "Y = e.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding\n",
    "Y_encoded = tf.keras.utils.to_categorical(Y)\n",
    "Y_encoded[0], Y_encoded[50], Y_encoded[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed 값 설정\n",
    "seed = 2020\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습셋과 테스트셋의 구분\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_encoded, test_size=0.2, \n",
    "                                                    random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 90)                5850      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                5824      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1950      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 18)                558       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                190       \n",
      "=================================================================\n",
      "Total params: 14,372\n",
      "Trainable params: 14,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정\n",
    "model = Sequential([\n",
    "    Dense(90, input_dim=64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(30, activation='relu'),\n",
    "    Dense(18, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 \n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 설정\n",
    "import os\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 조건 설정\n",
    "modelpath = MODEL_DIR + \"best{epoch:03d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "# checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1)\n",
    "checkpointer_callback = ModelCheckpoint(filepath=modelpath, monitor='val_loss', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.75415, saving model to ./model/best001-2.7541.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.75415 to 2.32277, saving model to ./model/best002-2.3228.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.32277 to 2.07860, saving model to ./model/best003-2.0786.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.07860 to 1.91561, saving model to ./model/best004-1.9156.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.91561 to 1.81373, saving model to ./model/best005-1.8137.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.81373 to 1.70394, saving model to ./model/best006-1.7039.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.70394 to 1.57633, saving model to ./model/best007-1.5763.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.57633 to 1.46009, saving model to ./model/best008-1.4601.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.46009 to 1.34522, saving model to ./model/best009-1.3452.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.34522 to 1.23983, saving model to ./model/best010-1.2398.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.23983 to 1.14816, saving model to ./model/best011-1.1482.hdf5\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.14816 to 1.05777, saving model to ./model/best012-1.0578.hdf5\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.05777 to 0.98136, saving model to ./model/best013-0.9814.hdf5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.98136 to 0.90489, saving model to ./model/best014-0.9049.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.90489 to 0.83231, saving model to ./model/best015-0.8323.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.83231 to 0.76685, saving model to ./model/best016-0.7668.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.76685 to 0.70791, saving model to ./model/best017-0.7079.hdf5\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.70791 to 0.64493, saving model to ./model/best018-0.6449.hdf5\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.64493 to 0.58894, saving model to ./model/best019-0.5889.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.58894 to 0.54173, saving model to ./model/best020-0.5417.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.54173 to 0.49633, saving model to ./model/best021-0.4963.hdf5\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.49633 to 0.45460, saving model to ./model/best022-0.4546.hdf5\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.45460 to 0.42413, saving model to ./model/best023-0.4241.hdf5\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.42413 to 0.39287, saving model to ./model/best024-0.3929.hdf5\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.39287 to 0.36242, saving model to ./model/best025-0.3624.hdf5\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.36242 to 0.33054, saving model to ./model/best026-0.3305.hdf5\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.33054 to 0.29250, saving model to ./model/best027-0.2925.hdf5\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.29250 to 0.26504, saving model to ./model/best028-0.2650.hdf5\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.26504 to 0.24289, saving model to ./model/best029-0.2429.hdf5\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.24289 to 0.21467, saving model to ./model/best030-0.2147.hdf5\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.21467 to 0.19233, saving model to ./model/best031-0.1923.hdf5\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19233 to 0.18761, saving model to ./model/best032-0.1876.hdf5\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.18761 to 0.17818, saving model to ./model/best033-0.1782.hdf5\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.17818 to 0.15429, saving model to ./model/best034-0.1543.hdf5\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.15429 to 0.14112, saving model to ./model/best035-0.1411.hdf5\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.14112\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.14112\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.14112\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.14112 to 0.13571, saving model to ./model/best039-0.1357.hdf5\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.13571 to 0.12990, saving model to ./model/best040-0.1299.hdf5\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.12990\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.12990\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.12990 to 0.12584, saving model to ./model/best043-0.1258.hdf5\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.12584 to 0.12090, saving model to ./model/best044-0.1209.hdf5\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.12090 to 0.11931, saving model to ./model/best045-0.1193.hdf5\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.11931\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.11931\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.11931\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.11931 to 0.11382, saving model to ./model/best049-0.1138.hdf5\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.11382 to 0.10915, saving model to ./model/best050-0.1091.hdf5\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.10915\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.10915 to 0.10845, saving model to ./model/best067-0.1084.hdf5\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.10845 to 0.10519, saving model to ./model/best068-0.1052.hdf5\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.10519 to 0.10394, saving model to ./model/best069-0.1039.hdf5\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.10394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00117: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.10394\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.10394\n"
     ]
    }
   ],
   "source": [
    "# 모델 실행 및 저장\n",
    "history = model.fit(X_train, Y_train, validation_split=0.2, epochs=3500, batch_size=500,\n",
    "                    verbose=0, callbacks=[early_stopping_callback, checkpointer_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360/360 - 0s - loss: 0.1071 - accuracy: 0.9750\n",
      "\n",
      " Accuracy: 0.9750\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model/best069-0.1039.hdf5')\n",
    "print(\"\\n Accuracy: %.4f\" % (model.evaluate(X_test, Y_test, verbose=2)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_vloss에 테스트셋으로 실험 결과의 오차 값을 저장\n",
    "y_vloss=history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_acc에 학습셋으로 측정한 정확도의 값을 저장\n",
    "y_acc=history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x 값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
    "x_len = np.arange(len(y_acc))\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.ylim(0,1)\n",
    "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=2)\n",
    "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=2)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
